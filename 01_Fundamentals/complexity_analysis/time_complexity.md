# â±ï¸ Time Complexity in Algorithms

---

## ğŸ”¹ 1. What is Time Complexity?

**Time Complexity** is a function that describes how the **running time of an algorithm grows** with respect to the size of the input `n`.

It helps us answer:
ğŸ‘‰ *â€œHow does the execution time scale as input grows?â€*

$$
T(n) = f(n)
$$

Where:

* `T(n)` â†’ time taken by algorithm for input size `n`.
* We care about **growth trend** rather than exact seconds.

---

## ğŸ”¹ 2. Why Do We Use Asymptotic Notation?

Since actual execution time depends on hardware, compiler, and system load â†’ we abstract it using **asymptotic notations**:

* **Big-O (O):** Upper bound (worst-case).
* **Omega (Î©):** Lower bound (best-case).
* **Theta (Î˜):** Tight bound (average-case).

Example:
Binary Search â†’ `O(log n)`, `Î©(1)`, `Î˜(log n)`.

---

## ğŸ”¹ 3. Step Counting Method

### Example: Sum of Array

```cpp
int sumArray(int arr[], int n) {
    int sum = 0;              // Step 1
    for (int i = 0; i < n; i++) {  // Step 2 â†’ executes n times
        sum += arr[i];        // Step 3 â†’ executes n times
    }
    return sum;               // Step 4
}
```

* Step 1 â†’ 1 operation
* Step 2 â†’ `n + 1` (last failure check)
* Step 3 â†’ `n`
* Step 4 â†’ 1

$$
T(n) = 2n + 3 = O(n)
$$

---

## ğŸ”¹ 4. Common Time Complexities

| Complexity     | Example Algorithm              | Growth Trend          |
| -------------- | ------------------------------ | --------------------- |
| **O(1)**       | Access array element           | Constant              |
| **O(log n)**   | Binary Search, Tree search     | Slow growth           |
| **O(n)**       | Linear Search                  | Linear                |
| **O(n log n)** | Merge Sort, QuickSort (avg)    | Faster than quadratic |
| **O(nÂ²)**      | Bubble Sort, Selection Sort    | Quadratic             |
| **O(2â¿)**      | Recursive Fibonacci            | Exponential           |
| **O(n!)**      | Traveling Salesman brute force | Factorial growth      |

ğŸ“Š Growth visualization:

```
O(1) < O(log n) < O(n) < O(n log n) < O(n^2) < O(2^n) < O(n!)
```

---

## ğŸ”¹ 5. Case Analysis

### Example: Binary Search

* **Best case:** `O(1)` â†’ element found at mid.
* **Worst case:** `O(log n)` â†’ keep halving until found.
* **Average case:** `O(log n)` â†’ balanced halving.

---

## ğŸ”¹ 6. Nested Loops

```cpp
for (int i = 0; i < n; i++) {       // O(n)
    for (int j = 0; j < n; j++) {   // O(n)
        // constant work
    }
}
```

$$
T(n) = O(n \times n) = O(n^2)
$$

---

## ğŸ”¹ 7. Logarithmic Complexity (Intuition)

Each iteration **shrinks the problem size** by a factor (commonly 2).

* Binary Search: search space halves â†’ `logâ‚‚n`.
* Tree height: balanced BST of `n` nodes has height â‰ˆ `logâ‚‚n`.

---

## ğŸ”¹ 8. Recurrence Relations

For recursive algorithms, we analyze time using **recurrence equations**.

### Example: Merge Sort

$$
T(n) = 2T\left(\frac{n}{2}\right) + O(n)
$$

Using **Master Theorem**:

$$
T(n) = O(n \log n)
$$

---

## ğŸ”¹ 9. Visual Aid

### Growth Rate Graph (ASCII Approximation)

```
n!
|
|                      *
|                  *
|              *
|          *
|      *
|   *
| *
|________________________________ n
 O(1) O(log n) O(n) O(n log n) O(n^2) O(2^n) O(n!)
```

---

## ğŸ”¹ 10. Variations & Edge Cases

* **Sparse input vs dense input** can change complexity.
* **Best-case optimizations** â†’ e.g., Bubble Sort stops early if sorted.
* **Hidden constants** matter in practice (e.g., O(n) with huge constants may be slower than O(n log n) for small `n`).

---

## ğŸ”¹ 11. Interview Tips

* Always state **best, worst, average cases**.
* Be ready to **derive complexity** by counting steps.
* For recursion: write recurrence and solve it.
* For FAANG: focus on `O(log n)`, `O(n)`, `O(n log n)` solutions.
* For GATE: expect derivations of recurrence relations and precise step counts.

---

## ğŸ”¹ 12. Practice Problems

* [LeetCode 704 â€“ Binary Search](https://leetcode.com/problems/binary-search/)
* [LeetCode 53 â€“ Maximum Subarray (Kadaneâ€™s Algo, O(n))](https://leetcode.com/problems/maximum-subarray/)
* [GFG â€“ Analysis of Algorithms](https://www.geeksforgeeks.org/analysis-of-algorithms-set-2-asymptotic-analysis/)
* [Codeforces â€“ Nested Loops Problems](https://codeforces.com/)

---

âœ… **Key Takeaway:**
Time complexity gives a **mathematical framework** to evaluate efficiency.
Mastering it requires **case analysis, recurrence solving, and recognizing common patterns**.

---
